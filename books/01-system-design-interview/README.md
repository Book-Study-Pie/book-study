<div align="center">
  <a href="https://product.kyobobook.co.kr/detail/S000001032980">
      <img src="./img/thumbnail.jpg" alt="Logo" width="200">
  </a>
  <h1>가상 면접 사례로 배우는 대규모 시스템 설계 기초</h1>
  <div>
    <img src="https://img.shields.io/badge/%EC%A0%80%EC%9E%90-%EC%95%8C%EB%9E%99%EC%8A%A4%20%EC%89%AC-e76f51?style=for-the-badge"/>
    <img src="https://img.shields.io/badge/%EC%B6%9C%ED%8C%90%EC%82%AC-%EC%9D%B8%EC%82%AC%EC%9D%B4%ED%8A%B8-faa307?style=for-the-badge"/>
    <img src="https://img.shields.io/badge/%EA%B8%B0%EA%B0%84-2025.02.01%20~%20%EC%A7%84%ED%96%89%EC%A4%91-52b788?style=for-the-badge"/>
  </div>
</div>

## 📝 목차
- [1장](#1장)
- [2 3장](#2-3장)
---

## 1장
> <strong><i>p9. 프로덕션(production)환경에서 벌어지는 일은 이것보다는 더 복잡한데, 부 서버에 보관된 데이터가 최신 상태가 아닐 수 있기 때문이다.</i></strong>

- `준기` : 찾아보니 `원형 다중화` 방식을 통해 빠른 동기화를 이룰 수 있지만 기존과 달리 한번의 쓰기에 대해 주,부 모든 데이터베이스에 모두 쓰기를 진행해야해서 쓰기 성능이 매우 떨어진다. 

> <strong><i>p9. 주 데이터베이스 서버가 다운되면, 한 대의 부 데이터베이스만 있는 경우 해당 부 데이터베이스 서버가 새로운 주 서버가 될 것이며, 모든 데이터베이스 연산은 일시적으로 새로운 주 서버상에서 수행될 것이다.</i></strong>
- `예슬`:  주와 부 데이터베이스 서버 간의 역할이 고정되지 않고 동적으로 변경될 수 있는 구조라는 것 깨달음. 대신 이 문장과 같은 기능을 수행하려면 MySQL에선 Group Replication을 통해 `SET GLOBAL`로 주 서버 자동 전환 설정을 해야 한다. <br>👉 [MySQL Group Replication 관련 문서 참고](https://saramin.github.io/2021-09-28-mysql-group-replication/)

> <strong><i>p12. 저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우 이 일관성은 깨질 수 있다.</i></strong>

- `준기` : 블로그 서비스의 CRUD 기능에서 R이 매우 중요하다. R에 캐시를 지원하도록 하고, CUD에서 캐시를 갱신하도록 해야한다. 해당 키의 캐시를 Evict해도 좋을 것 같다.

> <strong><i>p.13 캐시 메모리가 너무 작으면 액세스 패턴에 따라서는 데이터가 너무 자주 캐시에서 밀려나버려 캐시의 성능이 떨어지게 된다. 이를 막을 한 가지 방법은 캐시 메모리를 과할당하는 것이다.</i></strong>
- `예슬`: 과할당이 이러한 문제의 유일한 해결 방법이 아닐 거 같아 더 찾아보았더니 비효율적인 캐싱 전략이 그대로 유지되면 메모리를 늘려도 근본적인 문제는 해결되지 않는다는 것을 알아내었다.<br>`순차적 액세스 패턴`의 경우 LRU 정책을 사용해 자주 조회되는 데이터는 캐시에 오래 유지시키고, `랜덤 액세스 패턴`은 인기 있는 데이터를 프리로딩해 캐시에 미리 저장해 해결한다.<br>블로그 서비스처럼 한 번 작성되면 변동이 거의 없는 데이터에선 캐시를 활용하면 성능이 크게 향상되지만, 실시간 주식 가격 데이터는 자주 변경되므로 캐싱의 효과가 거의 없어지고 오히려 DB 부하가 증가한다. 따라서 쓰기 중심 데이터에서는 캐싱보다는 분산 DB나 NoSQL을 고려하는 것도 하나의 방법이다.

> <strong><i>p17. 웹 계층을 수평적으로 확장하기 위해 상태 정보(사용자 세션 데이터와 같은)를 웹 계층에서 제거하여야 한다.</i></strong>

- `준기` : 메모리 세션 로그인 방식이 아닌 토큰 방식 로그인을 사용하는 이유와 일맥상통한 것 같다.
   - `예슬`: 세션 로그인 방식의 문제점에 대해 더 찾아보았다.
     - 웹 서버 A에서 로그인한 사용자가 다음 요청을 보낼 때 웹 서버 B로 연결되면 웹 서버 A에 저장된 세션 정보가 B에서는 존재하지 않기 때문에 로그인 상태가 유지되지 않음
     - 이러한 문제 해결을 위해 `Sticky Session` 방식을 사용할 수 있지만 부하 분산의 효과를 저해한다.
> <strong><i>p23. 이러한 보정은 시간이 오래 걸릴 수 있는 프로세스이므로 비동기적으로 처리하면 편리하다. -> 메세지 큐를 이용한 비동기 처리 설명</i></strong>

- `준기` : 멀티 스레드를 활용해서 클라이언트의 두 가지 행동을 수행(일반적인 앱 이용, 사진보정요청수행)하도록 하면 되지 않을까? 무엇이 다른걸까?
   - `예슬`: 멀티 스레드는 요청을 저장하지 않지만, 메시지 큐는 요청을 큐에 저장해 보존할 수 있다. 따라서 프로세스 다운 시에도 메시지가 보존과 발행이 가능한지 가능하지 않은 지의 차이가 있다.<br>특히 나의 경우 `멀티 스레드`는 안드로이드 측에서 `UI블로킹을 방지`하기 위해 주로 사용하고 있다. 데이터베이스 처리 등을 안드로이드 메인 스레드에서 실행하면 앱이 멈추며 `ANR이 발생`하는데, 이러한 현상을 예방하고자 멀티 스레드를 사용한다. 이와 다르게 메시지 큐는 서버 측에서 `요청을 보존하며 안정적으로 처리하는 방식`이라 서로 다른 방식이라고 보면 된다.

> <strong><i>p28. 여러 샤드 서버로 쪼개고 나면, 여러 샤드에 걸친 데이터를 조인하기가 힘들어진다. 한 가지 방법은 데이터베이스를 비정규화하여 하나의 테이블에서 질의가 수행될 수 있도록 하는 것이다.</i></strong>

- `준기`: 데이터베이스의 기본은 데이터베이스 정규화인데 확장을 위해 거꾸로 가는 것 같은데.. 유일한 방법일까?
  - `예슬`: 데이터베이스 정규화의 목적을 생각해보면 <span style="color:indianred">데이터 중복을 줄이고 무결성을 보장</span>하는 것이다. 특히 유명인사 문제 등의 해결을 위해 여러 샤드 서버로 데이터를 분산하면 <span style="color:indianred">데이터의 정합성보다 확장성과 성능 최적화가 더 중요한 고려 요소</span>이며, 분산 환경에서는 조인 비용이 크기 때문에 정규화를 위한 데이터베이스 설계가 아닌 효율화를 위한 데이터베이스 설계를 진행해야 한다. <br>따라서 현재 구현하고자 하는 서비스의 규모와 필요한 데이터에 따라 비정규화도 충분히 합리적인 선택이라고 생각한다.


### ✅ 요약
1. 대규모 어플리케이션에서 기본적으로 고민할 지점은 수평적 확장 여부
2. 저장 계층의 수평적 확장시 데이터가 동기화 되는 시점과 기준 고민 필요

### 📘 정리글
- `준기` : [1장 정리글](https://velog.io/@aal2525/%EA%B0%80%EC%83%81-%EB%A9%B4%EC%A0%91-%EC%82%AC%EB%A1%80%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84-%EA%B8%B0%EC%B4%88-%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%97%90-%EB%94%B0%EB%A5%B8-%EA%B7%9C%EB%AA%A8-%ED%99%95%EC%9E%A5%EC%84%B1)
- `예슬` : [1장 정리글](https://velog.io/@yesue/%EA%B0%80%EC%83%81-%EB%A9%B4%EC%A0%91-%EC%82%AC%EB%A1%80%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84-%EA%B8%B0%EC%B4%88-1%EC%9E%A5.-%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%97%90-%EB%94%B0%EB%A5%B8-%EA%B7%9C%EB%AA%A8-%ED%99%95%EC%9E%A5%EC%84%B1)

## 2 3장
> <strong><i>p35. 데이터를 인터넷으로 전송하기 전에 가능하면 압축하라.</i></strong>

- `준기` : jpeg, png,webp등 이미지 파일은 대부분 자체적으로 압축된 포맷이기에 Gzip압축시 효과가 미미하거나 역 효과가 날 수 있으나 텍스트 기반의  json,csv의 경우 매우 큰 용량 절감을 볼 수 있다.

> <strong><i>p47 “99987/9.1”의 계산 결과는 무엇인가? 이런 데 시간을 쓰는 것은 낭비다.</i></strong>

- `준기` : 문제를 푸는 빌드업 도중 적절한 근사치를 활용해서 중요한 포인트에 빠르게 접근하자. 수학시험이 아니다.

> <strong><i>p41 속도를 늦춰라. 깊이 생각하고 질문하여 요구사항과 가정들을 분명히 하라.</i></strong>

- `준기` : 질문과 얻은 정보로 하여금 논리적 빌드업하는 연습을 해야할 것 같다. 무엇을 물어볼 지, 정보를 어떻게 쌓아나가 해결책까지 도달할 지.

> <strong><i>p46 상세 설계 : 이제 면접관과 해야 할 일은 설계 대상 컴포넌트 사이의 우선순위를 정하는 것이다.</i></strong>

- `준기` :  현재 진행하는 개인 프로젝트(블로그 서비스)에 맞추어 설명해보자면 게시글 조회 수가 많을 때 캐싱 전략을 어떻게 적용할 것인지, 특정 게시물 바이럴 등의 상황으로 트래픽이 급증할 경우 스케일링을 어떻게 처리할 것인지 설명할 수 있어야 한다.

> <strong><i>p34 구글의 제프 딘은 2010년 통상적인 컴퓨터에서 구현된 연산들의 응답지연 값을 공개한 바 있다.</i></strong>

- `준기` :  GPT 4o의 개발자들이 관심있을만한 연산들의 응답 지연 시간 표 정리

| **연산** | **응답 시간 (대략)** | **설명** |
|----------|----------------|------------------------------|
| **RAM 접근** | **~100-150ns** | 메모리에서 직접 읽기 |
| **PCIe NVMe SSD 읽기** | **~10-100µs** | 초고속 SSD에서 데이터 로드 |
| **로컬 SSD 읽기** | **~100-300µs** | 일반적인 SSD에서 데이터 읽기 |
| **로컬 HDD 읽기** | **~1-10ms** | 기계식 하드디스크 접근 |
| **AWS S3에서 1MB 파일 가져오기** | **~20-100ms** | 지역 내 S3 객체 다운로드 |
| **데이터베이스 인덱스 조회 (Redis, Memcached)** | **~0.5-1ms** | 인메모리 데이터베이스 조회 |
| **SQL 쿼리 실행 (단순 SELECT, 인덱스 있음)** | **~1-10ms** | 일반적인 관계형 데이터베이스 조회 |
| **SQL 쿼리 실행 (조인, 대량 데이터)** | **~10ms - 1s+** | 복잡한 조인 연산 포함 |
| **Kafka 메시지 처리 (단일 메시지 소비)** | **~1-10ms** | 스트리밍 데이터 소비 속도 |
| **HTTP 요청 (같은 데이터센터 내)** | **~0.5-5ms** | 클라우드 내 마이크로서비스 호출 |
| **HTTP 요청 (인터넷, 다른 지역 서버)** | **~50-300ms** | AWS US → EU 요청 |
| **GPT-4 API 응답 시간** | **~300ms - 2s** | OpenAI API 호출 |
| **LLM 모델 로컬 실행 (CPU, 7B 모델)** | **~500ms - 5s** | 일반 PC에서 LLM 실행 |
| **LLM 모델 로컬 실행 (GPU, 7B 모델)** | **~50-300ms** | GPU 사용 시 속도 향상 |
| **Stable Diffusion 이미지 생성 (512x512, CPU)** | **~30-120s** | 딥러닝 기반 이미지 생성 |
| **Stable Diffusion 이미지 생성 (512x512, GPU)** | **~1-5s** | GPU 최적화 시 성능 향상 |
| **CDN을 통한 정적 파일 요청 (CSS, JS, 이미지 등)** | **~10-50ms** | 캐싱된 콘텐츠 다운로드 |


### ✅ 요약
1. 
2. 

### 📘 정리글
- `준기` : [2장 정리글](https://velog.io/@aal2525/%EA%B0%80%EC%83%81-%EB%A9%B4%EC%A0%91-%EC%82%AC%EB%A1%80%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84-%EA%B8%B0%EC%B4%88-%EA%B0%9C%EB%9E%B5%EC%A0%81%EC%9D%B8-%EA%B7%9C%EB%AA%A8-%EC%B6%94%EC%A0%95)
          [3장 정리글](https://velog.io/@aal2525/%EA%B0%80%EC%83%81-%EB%A9%B4%EC%A0%91-%EC%82%AC%EB%A1%80%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84-%EA%B8%B0%EC%B4%88-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84-%EB%A9%B4%EC%A0%91-%EA%B3%B5%EB%9E%B5%EB%B2%95)
- `예슬` : 